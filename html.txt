<!DOCTYPE html>
<!--[if IE 6]><html class="ie lt-ie8"><![endif]-->
<!--[if IE 7]><html class="ie lt-ie8"><![endif]-->
<!--[if IE 8]><html class="ie ie8"><![endif]-->
<!--[if IE 9]><html class="ie ie9"><![endif]-->
<!--[if !IE]><!--> <html> <!--<![endif]-->

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0,user-scalable=no">

  <!-- Start of Baidu Transcode -->
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta name="applicable-device" content="pc,mobile">
  <meta name="MobileOptimized" content="width"/>
  <meta name="HandheldFriendly" content="true"/>
  <meta name="mobile-agent" content="format=html5;url=https://www.jianshu.com/p/77a2e09b5285">
  <!-- End of Baidu Transcode -->

    <meta name="description"  content="用Python开发一个简单爬虫非常简单，10多行代码即可完成，实现功能。 1、获取网页代码 就是将互联网上URL对应的网页下载到本地（内存）中。再进行内容分析和提取。 这部分要实现的功能，相当于浏览器，当我们在浏览器上输入一个URL地址，是向远程服务器发送一个请求，远程服务器把源代码通过网络传送到客户端的浏览器，由浏览器进行解析呈现。我们通常在网页上右键--“显示网页源代码”，看到的代码就是...">

  <meta name="360-site-verification" content="604a14b53c6b871206001285921e81d8" />
  <meta property="wb:webmaster" content="294ec9de89e7fadb" />
  <meta property="qc:admins" content="104102651453316562112116375" />
  <meta property="qc:admins" content="11635613706305617" />
  <meta property="qc:admins" content="1163561616621163056375" />
  <meta name="google-site-verification" content="cV4-qkUJZR6gmFeajx_UyPe47GW9vY6cnCrYtCHYNh4" />
  <meta name="google-site-verification" content="HF7lfF8YEGs1qtCE-kPml8Z469e2RHhGajy6JPVy5XI" />
  <meta http-equiv="mobile-agent" content="format=html5; url=https://www.jianshu.com/p/77a2e09b5285">

  <!-- Apple -->
  <meta name="apple-mobile-web-app-title" content="简书">

    <!--  Meta for Smart App Banner -->
  <meta name="apple-itunes-app" content="app-id=888237539, app-argument=jianshu://notes/3845336">
  <!-- End -->

  <!--  Meta for Twitter Card -->
  <meta content="summary" property="twitter:card">
  <meta content="@jianshucom" property="twitter:site">
  <meta content="10行代码完成一个爬虫，就这么简单" property="twitter:title">
  <meta content="用Python开发一个简单爬虫非常简单，10多行代码即可完成，实现功能。 1、获取网页代码 就是将互联网上URL对应的网页下载到本地（内存）中。再进行内容分析和提取。 这部分..." property="twitter:description">
  <meta content="https://www.jianshu.com/p/77a2e09b5285" property="twitter:url">
  <!-- End -->

  <!--  Meta for OpenGraph -->
  <meta property="fb:app_id" content="865829053512461">
  <meta property="og:site_name" content="简书">
  <meta property="og:title" content="10行代码完成一个爬虫，就这么简单">
  <meta property="og:type" content="article">
  <meta property="og:url" content="https://www.jianshu.com/p/77a2e09b5285">
  <meta property="og:description" content="用Python开发一个简单爬虫非常简单，10多行代码即可完成，实现功能。 1、获取网页代码 就是将互联网上URL对应的网页下载到本地（内存）中。再进行内容分析和提取。 这部分要实现的功能，相当于...">
  <!-- End -->

  <!--  Meta for Facebook Applinks -->
  <meta property="al:ios:url" content="jianshu://notes/3845336" />
  <meta property="al:ios:app_store_id" content="888237539" />
  <meta property="al:ios:app_name" content="简书" />

  <meta property="al:android:url" content="jianshu://notes/3845336" />
  <meta property="al:android:package" content="com.jianshu.haruki" />
  <meta property="al:android:app_name" content="简书" />
  <!-- End -->


    <title>10行代码完成一个爬虫，就这么简单 - 简书</title>

  <meta name="csrf-param" content="authenticity_token" />
<meta name="csrf-token" content="/tFR6NmX7+hepTWeQWYLdFkiXyRPNPc+J370OGp7G8b3xoETYIlMUbnR4d27QVX0R2VBFmJI7tL3A1fciigCDA==" />

  <link rel="stylesheet" media="all" href="//cdn2.jianshu.io/assets/web-bd0e74f69439789d683b.css" />
  
  <link rel="stylesheet" media="all" href="//cdn2.jianshu.io/assets/web/pages/notes/show/entry-26b7d612b78d3be06fb9.css" />

  <link href="//cdn2.jianshu.io/assets/favicons/favicon-e743bfb1821442341c3ab15bdbe804f7ad97676bd07a770ccc9483473aa76f06.ico" rel="shortcut icon" type="image/x-icon">
      <link rel="apple-touch-icon-precomposed" href="//cdn2.jianshu.io/assets/apple-touch-icons/57-a6f1f1ee62ace44f6dc2f6a08575abd3c3b163288881c78dd8d75247682a4b27.png" sizes="57x57" />
      <link rel="apple-touch-icon-precomposed" href="//cdn2.jianshu.io/assets/apple-touch-icons/72-fb9834bcfce738fd7b9c5e31363e79443e09a81a8e931170b58bc815387c1562.png" sizes="72x72" />
      <link rel="apple-touch-icon-precomposed" href="//cdn2.jianshu.io/assets/apple-touch-icons/76-49d88e539ff2489475d603994988d871219141ecaa0b1a7a9a1914f4fe3182d6.png" sizes="76x76" />
      <link rel="apple-touch-icon-precomposed" href="//cdn2.jianshu.io/assets/apple-touch-icons/114-24252fe693524ed3a9d0905e49bff3cbd0228f25a320aa09053c2ebb4955de97.png" sizes="114x114" />
      <link rel="apple-touch-icon-precomposed" href="//cdn2.jianshu.io/assets/apple-touch-icons/120-1bb7371f5e87f93ce780a5f1a05ff1b176828ee0d1d130e768575918a2e05834.png" sizes="120x120" />
      <link rel="apple-touch-icon-precomposed" href="//cdn2.jianshu.io/assets/apple-touch-icons/152-bf209460fc1c17bfd3e2b84c8e758bc11ca3e570fd411c3bbd84149b97453b99.png" sizes="152x152" />

  <!-- Start of 访问统计 -->
    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?0c0e9d9b1e7d617b3e6842e85b9fb068";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>

  <!-- End of 访问统计 -->
</head>

  <body lang="zh-CN" class="reader-black-font">
    <!-- 全局顶部导航栏 -->
<nav class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="width-limit">
    <!-- 左上方 Logo -->
    <a class="logo" href="/"><img src="//cdn2.jianshu.io/assets/web/nav-logo-4c7bbafe27adc892f3046e6978459bac.png" alt="Nav logo" /></a>

    <!-- 右上角 -->
      <!-- 未登录显示登录/注册/写文章 -->
      <a class="btn write-btn" target="_blank" href="/writer#/">
        <i class="iconfont ic-write"></i>写文章
</a>      <a class="btn sign-up" href="/sign_up">注册</a>
      <a class="btn log-in" href="/sign_in">登录</a>

    <!-- 如果用户登录，显示下拉菜单 -->

    <div id="view-mode-ctrl">
    </div>
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#menu" aria-expanded="false">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
      </div>
      <div class="collapse navbar-collapse" id="menu">
        <ul class="nav navbar-nav">
            <li class="tab ">
              <a href="/">
                <span class="menu-text">首页</span><i class="iconfont ic-navigation-discover menu-icon"></i>
</a>            </li>
            <li class="tab ">
              <a id="web-nav-app-download-btn" class="app-download-btn" href="/apps?utm_medium=desktop&amp;utm_source=navbar-apps"><span class="menu-text">下载App</span><i class="iconfont ic-navigation-download menu-icon"></i></a>
            </li>
          <li class="search">
            <form target="_blank" action="/search" accept-charset="UTF-8" method="get"><input name="utf8" type="hidden" value="&#x2713;" />
              <input type="text" name="q" id="q" value="" autocomplete="off" placeholder="搜索" class="search-input" />
              <a class="search-btn" href="javascript:void(null)"><i class="iconfont ic-search"></i></a>
</form>          </li>
        </ul>
      </div>
    </div>
  </div>
</nav>

    
<div class="note">
  <a target="_blank" href="/apps/download?utm_source=sbc" id="web-note-ad-fixed"><span class="close">&times;</span></a>
  <div class="post">
    <div class="article">
        <h1 class="title">10行代码完成一个爬虫，就这么简单</h1>

        <!-- 作者区域 -->
        <div class="author">
          <a class="avatar" href="/u/54b5900965ea">
            <img src="//upload.jianshu.io/users/upload_avatars/938707/a9b1aa2c94db?imageMogr2/auto-orient/strip|imageView2/1/w/96/h/96" alt="96" />
</a>          <div class="info">
            <span class="name"><a href="/u/54b5900965ea">向右奔跑</a></span>
            <!-- 关注用户按钮 -->
            <div props-data-classes="user-follow-button-header" data-author-follow-button></div>
            <!-- 文章数据信息 -->
            <div class="meta">
              <!-- 如果文章更新时间大于发布时间，那么使用 tooltip 显示更新时间 -->
                <span class="publish-time" data-toggle="tooltip" data-placement="bottom" title="最后编辑于 2017.12.03 05:10">2016.05.07 02:41*</span>
              <span class="wordage">字数 868</span>
            </div>
          </div>
          <!-- 如果是当前作者，加入编辑按钮 -->
        </div>

        <!-- 文章内容 -->
        <div data-note-content class="show-content">
          <div class="show-content-free">
            <p>用Python开发一个简单爬虫非常简单，10多行代码即可完成，实现功能。</p>
<h3>1、获取网页代码</h3>
<p>就是将互联网上URL对应的网页下载到本地（内存）中。再进行内容分析和提取。</p>
<p>这部分要实现的功能，相当于浏览器，当我们在浏览器上输入一个URL地址，是向远程服务器发送一个请求，远程服务器把源代码通过网络传送到客户端的浏览器，由浏览器进行解析呈现。我们通常在网页上右键--“显示网页源代码”，看到的代码就是服务器端传输过来的。现在要以编程的方式拿到这些代码。</p>
<p><strong>获取网页的方式，有urlib, urllib2, requests三种方法。</strong><br>
urlib和urllib2是Python提供的基础模块。 requests是Python提供的第三方库，功能更为强大。</p>
<blockquote>
<p>urllib2<br>
can accept a Request object to set the headers for a URL request,urllib<br>
accepts only a URL. That means, you cannot masquerade your User Agent string etc.</p>
</blockquote>
<blockquote>
<p>urllib2可以接受一个<strong>Request</strong>类的实例来设置URL请求的headers，urllib仅可以接受URL。这意味着，你不可以伪装你的User Agent字符串等。<br>
（就是用urllib2可以提交Cookie数据，实现模拟登录）</p>
</blockquote>
<blockquote>
<p>urllib<br>
provides the urlencode method which is used for the generation of GET query strings, urllib2<br>
doesn't have such a function. This is one of the reasons why urllib<br>
is often used along with urllib2</p>
</blockquote>
<blockquote>
<p>urllib提供<strong>urlencode</strong>方法用来GET查询字符串的产生，而urllib2没有。这是为何urllib常和urllib2一起使用的原因。</p>
</blockquote>
<p>看一下实现的代码，共<strong>4</strong>行代码，使用的是urllib2：</p>
<pre><code>def getHtml(url):   
  page = urllib.urlopen(url)    
  html = page.read()    
  return html
</code></pre>
<p>拿到代码可以在控制台打印输出看一下。</p>
<h3>2、提取相应内容</h3>
<p>就是对拿到的网页源代码进行匹配，检索解析出需要的内容。如爬取网站上所有的图片，就是要分析出图片的url（img 标签的 src）</p>
<p>网页解析，提取内容的方式有正则表达式，BeautifulSoup，XPath。</p>
<ul>
<li>Beautiful Soup是Python的一个库，最主要的功能是从网页抓取数据。</li>
<li>XPath 是一门在 XML 文档中查找信息的语言。XPath 可用来在 XML 文档中对元素和属性进行遍历。</li>
</ul>
<p>简单来说，正则表达式就是要描述出所要提取内容周边元素，采用模糊匹配的方式，XPath是指定一个路径来查找所要的内容。</p>
<p>拿到数据的关键是要熟悉网页的结构。XPath 是需要知道文档的层级结构, Beautiful Soup可以通过某些标签来直接查找。</p>
<p>(以爬取简书首页 文章标题，链接，阅读量，评论量为例)</p>
<div class="image-package">
<div class="image-container" style="max-width: 554px; max-height: 397px;">
<div class="image-container-fill" style="padding-bottom: 71.66%;"></div>
<div class="image-view" data-width="554" data-height="397"><img data-original-src="//upload-images.jianshu.io/upload_images/938707-4f6d375ddf9a8770.png" data-original-width="554" data-original-height="397" data-original-format="image/png" data-original-filesize="89091"></div>
</div>
<div class="image-caption">这是文档中文章 标签及结构</div>
</div>
<h5>写出正则表达式：</h5>
<pre><code>reg = r'&lt;h4 class="title"&gt;&lt;a target="_blank" href="(.*?)"&gt;(.*?)&lt;/a&gt;&lt;/h4&gt;[\n][\s]+&lt;div class="list-footer"&gt;[\n][\s]+&lt;a target="_blank" href="/p/.*?"&gt;[\n][\s]+(.*?)[\n]&lt;/a&gt;[\s]+&lt;a target="_blank" href=".*?"&gt;[\n][\s]+(.*?)[\n]&lt;/a&gt;[\s]+&lt;span&gt;(.*?)&lt;/span&gt;'

</code></pre>
<p>(注意，有换行和空白)</p>
<h5>用正则表达式去匹配，获得结果</h5>
<pre><code>hotre = re.compile(reg)
artlist = re.findall(hotre, html)
</code></pre>
<h3>3、输出分析内容</h3>
<p>进行统计，输出到Excel或其他文件、数据库中。</p>
<p>以控制台的打印输出为例：</p>
<pre><code>for article in artlist:    
  for com in article:      
      if com.startswith("/p/"):           
          print "http://www.jianshu.com"+com       
      else:           
          print com
</code></pre>
<div class="image-package">
<div class="image-container" style="max-width: 420px; max-height: 463px;">
<div class="image-container-fill" style="padding-bottom: 110.24000000000001%;"></div>
<div class="image-view" data-width="420" data-height="463"><img data-original-src="//upload-images.jianshu.io/upload_images/938707-6bcb76bad22e917b.png" data-original-width="420" data-original-height="463" data-original-format="image/png" data-original-filesize="95668"></div>
</div>
<div class="image-caption">爬取的数据</div>
</div>
<h5>完整代码：</h5>
<pre><code>#coding=utf-8
import re
import urllib

def getHtml(url):
    page = urllib.urlopen(url)
    html = page.read()
    return html

html = getHtml("http://www.jianshu.com")
reg = r'&lt;h4 class="title"&gt;&lt;a target="_blank" href="(.*?)"&gt;(.*?)&lt;/a&gt;&lt;/h4&gt;[\n][\s]+&lt;div class="list-footer"&gt;[\n][\s]+&lt;a target="_blank" href="/p/.*?"&gt;[\n][\s]+(.*?)[\n]&lt;/a&gt;[\s]+&lt;a target="_blank" href=".*?"&gt;[\n][\s]+(.*?)[\n]&lt;/a&gt;[\s]+&lt;span&gt;(.*?)&lt;/span&gt;'
hotre = re.compile(reg)
artlist = re.findall(hotre, html)

for article in artlist:
    for com in article:
        if com.startswith("/p/"):
            print "http://www.jianshu.com"+com
        else:
            print com
</code></pre>
<h3>总结：</h3>
<ol>
<li>对HTML网页结构要清晰。</li>
<li>正则表达式要熟悉，是提取数据的关键。<br>
使用BeautifulSoup会简单很多，里面也会用到正则。</li>
</ol>
<p>就是这么简单，就是这么好用。</p>

          </div>
        </div>
    </div>

    <!-- 连载目录项 -->

    <!-- 打赏文章、购买文章、购买连载 -->
        <div data-vcomp="free-reward-panel"></div>

      <div class="show-foot">
        <a class="notebook" href="/nb/4204686">
          <i class="iconfont ic-search-notebook"></i>
          <span>Python爬虫</span>
</a>        <div class="copyright" data-toggle="tooltip" data-html="true" data-original-title="转载请联系作者获得授权，并标注“简书作者”。">
          © 著作权归作者所有
        </div>
        <div class="modal-wrap" data-report-note>
          <a id="report-modal">举报文章</a>
        </div>
      </div>

      <!-- 文章底部作者信息 -->
        <div class="follow-detail">
          <div class="info">
            <a class="avatar" href="/u/54b5900965ea">
              <img src="//upload.jianshu.io/users/upload_avatars/938707/a9b1aa2c94db?imageMogr2/auto-orient/strip|imageView2/1/w/96/h/96" alt="96" />
</a>            <div props-data-classes="user-follow-button-footer" data-author-follow-button></div>
            <a class="title" href="/u/54b5900965ea">向右奔跑</a>
            
          </div>
            <div class="signature">抓住了，生命开始加速！</div>
        </div>

    <div class="meta-bottom">
      <div class="btn like-group"></div>
      <div class="share-group">
        <a class="share-circle" data-action="weixin-share" data-toggle="tooltip" data-original-title="分享到微信">
          <i class="iconfont ic-wechat"></i>
        </a>
        <a class="share-circle" data-action="weibo-share" data-toggle="tooltip" href="javascript:void((function(s,d,e,r,l,p,t,z,c){var%20f=&#39;http://v.t.sina.com.cn/share/share.php?appkey=1881139527&#39;,u=z||d.location,p=[&#39;&amp;url=&#39;,e(u),&#39;&amp;title=&#39;,e(t||d.title),&#39;&amp;source=&#39;,e(r),&#39;&amp;sourceUrl=&#39;,e(l),&#39;&amp;content=&#39;,c||&#39;gb2312&#39;,&#39;&amp;pic=&#39;,e(p||&#39;&#39;)].join(&#39;&#39;);function%20a(){if(!window.open([f,p].join(&#39;&#39;),&#39;mb&#39;,[&#39;toolbar=0,status=0,resizable=1,width=440,height=430,left=&#39;,(s.width-440)/2,&#39;,top=&#39;,(s.height-430)/2].join(&#39;&#39;)))u.href=[f,p].join(&#39;&#39;);};if(/Firefox/.test(navigator.userAgent))setTimeout(a,0);else%20a();})(screen,document,encodeURIComponent,&#39;&#39;,&#39;&#39;,&#39;&#39;, &#39;推荐 @向右奔跑 的文章《10行代码完成一个爬虫，就这么简单》（ 分享自 @简书 ）&#39;,&#39;https://www.jianshu.com/p/77a2e09b5285?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=weibo&#39;,&#39;页面编码gb2312|utf-8默认gb2312&#39;));" data-original-title="分享到微博">
          <i class="iconfont ic-weibo"></i>
        </a>
          <a class="share-circle" data-toggle="tooltip" href="http://cwb.assets.jianshu.io/notes/images/3845336/weibo/image_e2c7fd24671a.jpg" target="_blank" data-original-title="下载长微博图片">
            <i class="iconfont ic-picture"></i>
          </a>
        <a class="share-circle more-share" tabindex="0" data-toggle="popover" data-placement="top" data-html="true" data-trigger="focus" href="javascript:void(0);" data-content='
          <ul class="share-list">
            <li><a href="javascript:void(function(){var d=document,e=encodeURIComponent,r=&#39;http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=&#39;+e(&#39;https://www.jianshu.com/p/77a2e09b5285?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=qzone&#39;)+&#39;&amp;title=&#39;+e(&#39;推荐 向右奔跑 的文章《10行代码完成一个爬虫，就这么简单》&#39;),x=function(){if(!window.open(r,&#39;qzone&#39;,&#39;toolbar=0,resizable=1,scrollbars=yes,status=1,width=600,height=600&#39;))location.href=r};if(/Firefox/.test(navigator.userAgent)){setTimeout(x,0)}else{x()}})();"><i class="social-icon-sprite social-icon-zone"></i><span>分享到QQ空间</span></a></li>
            <li><a href="javascript:void(function(){var d=document,e=encodeURIComponent,r=&#39;https://twitter.com/share?url=&#39;+e(&#39;https://www.jianshu.com/p/77a2e09b5285?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=twitter&#39;)+&#39;&amp;text=&#39;+e(&#39;推荐 向右奔跑 的文章《10行代码完成一个爬虫，就这么简单》（ 分享自 @jianshucom ）&#39;)+&#39;&amp;related=&#39;+e(&#39;jianshucom&#39;),x=function(){if(!window.open(r,&#39;twitter&#39;,&#39;toolbar=0,resizable=1,scrollbars=yes,status=1,width=600,height=600&#39;))location.href=r};if(/Firefox/.test(navigator.userAgent)){setTimeout(x,0)}else{x()}})();"><i class="social-icon-sprite social-icon-twitter"></i><span>分享到Twitter</span></a></li>
            <li><a href="javascript:void(function(){var d=document,e=encodeURIComponent,r=&#39;https://www.facebook.com/dialog/share?app_id=483126645039390&amp;display=popup&amp;href=https://www.jianshu.com/p/77a2e09b5285?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=facebook&#39;,x=function(){if(!window.open(r,&#39;facebook&#39;,&#39;toolbar=0,resizable=1,scrollbars=yes,status=1,width=450,height=330&#39;))location.href=r};if(/Firefox/.test(navigator.userAgent)){setTimeout(x,0)}else{x()}})();"><i class="social-icon-sprite social-icon-facebook"></i><span>分享到Facebook</span></a></li>
            <li><a href="javascript:void(function(){var d=document,e=encodeURIComponent,r=&#39;https://plus.google.com/share?url=&#39;+e(&#39;https://www.jianshu.com/p/77a2e09b5285?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=google_plus&#39;),x=function(){if(!window.open(r,&#39;google_plus&#39;,&#39;toolbar=0,resizable=1,scrollbars=yes,status=1,width=450,height=330&#39;))location.href=r};if(/Firefox/.test(navigator.userAgent)){setTimeout(x,0)}else{x()}})();"><i class="social-icon-sprite social-icon-google"></i><span>分享到Google+</span></a></li>
            <li><a href="javascript:void(function(){var d=document,e=encodeURIComponent,s1=window.getSelection,s2=d.getSelection,s3=d.selection,s=s1?s1():s2?s2():s3?s3.createRange().text:&#39;&#39;,r=&#39;http://www.douban.com/recommend/?url=&#39;+e(&#39;https://www.jianshu.com/p/77a2e09b5285?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=douban&#39;)+&#39;&amp;title=&#39;+e(&#39;10行代码完成一个爬虫，就这么简单&#39;)+&#39;&amp;sel=&#39;+e(s)+&#39;&amp;v=1&#39;,x=function(){if(!window.open(r,&#39;douban&#39;,&#39;toolbar=0,resizable=1,scrollbars=yes,status=1,width=450,height=330&#39;))location.href=r+&#39;&amp;r=1&#39;};if(/Firefox/.test(navigator.userAgent)){setTimeout(x,0)}else{x()}})()"><i class="social-icon-sprite social-icon-douban"></i><span>分享到豆瓣</span></a></li>
          </ul>
        '>更多分享</a>
      </div>
    </div>
      <a id="web-note-ad-1" target="_blank" href="/apps/download?utm_source=nbc"><img src="//cdn2.jianshu.io/assets/web/web-note-ad-1-10f08e404d3887d2d45a4bc8f1831403.png" alt="Web note ad 1" /></a>
    <div id="vue_comment"></div>
  </div>

  <div class="vue-side-tool" props-data-props-show-qr-code="0"></div>
</div>
<div class="note-bottom">
  <div class="js-included-collections"></div>
  <div data-vcomp="recommended-notes" data-lazy="1.5" data-note-id="3845336"></div>
  <!-- 相关文章 -->
  <div class="seo-recommended-notes">

        <div class="note have-img">
          <a class="cover" target="_blank" href="/p/0bfd0c48457f?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
            <img src="//upload-images.jianshu.io/upload_images/3471485-fe45807df6553906.png?imageMogr2/auto-orient/strip|imageView2/1/w/300/h/240" alt="240" />
</a>          <a class="title" target="_blank" href="/p/0bfd0c48457f?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">爬虫（1）--- Python网络爬虫二三事</a>
          <p class="description">1 前言 作为一名合格的数据分析师，其完整的技术知识体系必须贯穿数据获取、数据存储、数据提取、数据分析、数据挖掘、数据可视化等各大部分。在此作为初出茅庐的数据小白，我将会把自己学习数据科学过程中遇到的一些问题记录下来，以便后续的查阅，同时也希望与各路同学一起交流、一起进步。...</p>
          <a class="author" target="_blank" href="/u/51c2a335b8a1?utm_campaign=maleskine&amp;utm_content=user&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
            <div class="avatar">
              <img src="//upload.jianshu.io/users/upload_avatars/3471485/617d85f4b304?imageMogr2/auto-orient/strip|imageView2/1/w/48/h/48" alt="48" />
            </div>
            <span class="name">whenif</span>
</a>        </div>

        <div class="note ">
                    <a class="title" target="_blank" href="/p/d4ebace4ddcf?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">爬虫</a>
          <p class="description">抓取网页1）直接抓取网页法 注意导入模块一定要写成urllib.request，urllib.parse等等。urllib2模块在Python3已拆分更名为urllib.request和urllib.error。写成import urllib会出错：&#39;module&#39; obj...</p>
          <a class="author" target="_blank" href="/u/569fc47cc389?utm_campaign=maleskine&amp;utm_content=user&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
            <div class="avatar">
              <img src="//upload.jianshu.io/users/upload_avatars/59989/07a640c774a1.jpg?imageMogr2/auto-orient/strip|imageView2/1/w/48/h/48" alt="48" />
            </div>
            <span class="name">dropwater</span>
</a>        </div>

        <div class="note ">
                    <a class="title" target="_blank" href="/p/5c12b5eb6be5?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">Python 系列（二）- 收藏集 - 掘金</a>
          <p class="description">Python 函数式编程入门教程 - 后端 - 掘金本文为作者原创，转载请先与作者联系。同发于博客园和 SegmentFault专栏 Functional Programming 引言 Functional Programming(函数式编程)的概念最早起源于LISP，由约...</p>
          <a class="author" target="_blank" href="/u/5fc9b6410f4f?utm_campaign=maleskine&amp;utm_content=user&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
            <div class="avatar">
              <img src="//upload.jianshu.io/users/upload_avatars/120495/6220dd63-bf1a-40a8-8ccc-e364a5c90f13.png?imageMogr2/auto-orient/strip|imageView2/1/w/48/h/48" alt="48" />
            </div>
            <span class="name">掘金官方</span>
</a>        </div>

        <div class="note have-img">
          <a class="cover" target="_blank" href="/p/8b2712d8b29b?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
            <img src="//upload-images.jianshu.io/upload_images/2106579-e9a3fbcb923847d0.png?imageMogr2/auto-orient/strip|imageView2/1/w/300/h/240" alt="240" />
</a>          <a class="title" target="_blank" href="/p/8b2712d8b29b?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">Python爬虫入门（urllib+Beautifulsoup）</a>
          <p class="description">Python爬虫入门（urllib+Beautifulsoup） 本文包括：1、爬虫简单介绍2、爬虫架构三大模块3、urllib4、BeautifulSoup5、实战演练：爬取百度百科1000个页面 1、爬虫简单介绍 爬虫：一段自动抓取互联网信息的程序 从一个url出发，然...</p>
          <a class="author" target="_blank" href="/u/28b41b12cde8?utm_campaign=maleskine&amp;utm_content=user&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
            <div class="avatar">
              <img src="//upload.jianshu.io/users/upload_avatars/2106579/568913636b7f.jpg?imageMogr2/auto-orient/strip|imageView2/1/w/48/h/48" alt="48" />
            </div>
            <span class="name">廖少少</span>
</a>        </div>

        <div class="note have-img">
          <a class="cover" target="_blank" href="/p/14288e998a5a?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
            <img src="//upload-images.jianshu.io/upload_images/2391750-a1338650913ebe68.png?imageMogr2/auto-orient/strip|imageView2/1/w/300/h/240" alt="240" />
</a>          <a class="title" target="_blank" href="/p/14288e998a5a?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">第一章网络爬虫简介</a>
          <p class="description">本章中，我们将会介绍如下主题： 网络爬虫领域简介； 解释合法性质疑； 对目标网站进行背景调研； 逐步完善一个高级网络爬虫。 1.1网络爬虫何时有用 假设我有一个鞋店，并且想要及时了解竞争对手的价格。我可以每天访问他们的网站，与我店铺中鞋子的价格进行对比。但是，如果我店铺中的...</p>
          <a class="author" target="_blank" href="/u/811679f3930a?utm_campaign=maleskine&amp;utm_content=user&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
            <div class="avatar">
              <img src="//cdn2.jianshu.io/assets/default_avatar/3-9a2bcc21a5d89e21dafc73b39dc5f582.jpg?imageMogr2/auto-orient/strip|imageView2/1/w/48/h/48" alt="48" />
            </div>
            <span class="name">世界百科</span>
</a>        </div>

        <div class="note ">
                    <a class="title" target="_blank" href="/p/a819322c64f4?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">《月》</a>
          <p class="description">                          《月》    江畔何人初见月，江月和年初照人            …… 唐……张若虚  小的时候读《春江花月夜》每每读到这两句便会有莫名的感动。后来读书多了方领悟这是中国古代诗人在思索宇宙和人类的的生成。 观赏秋的枫叶 ...</p>
          <a class="author" target="_blank" href="/u/b09ccbc35031?utm_campaign=maleskine&amp;utm_content=user&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
            <div class="avatar">
              <img src="//upload.jianshu.io/users/upload_avatars/4611311/4385c7df8aef.jpg?imageMogr2/auto-orient/strip|imageView2/1/w/48/h/48" alt="48" />
            </div>
            <span class="name">王河</span>
</a>        </div>

        <div class="note have-img">
          <a class="cover" target="_blank" href="/p/1a9a4aa03090?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
            <img src="//upload-images.jianshu.io/upload_images/6278888-10a2df62670c58e2.png?imageMogr2/auto-orient/strip|imageView2/1/w/300/h/240" alt="240" />
</a>          <a class="title" target="_blank" href="/p/1a9a4aa03090?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">第一次徒步旅行，全程怂到底，却也收获多多</a>
          <p class="description">    2017年5月20日，在这个满城皆是虐狗的日子，我和朋友选择躲到深山野林，回归大自然的怀抱，当然部分原因还是想着毕竟眼不见为净嘛。 意外的32号     我们参加了一个专门带团徒步的团队，叫做32号。原本很好奇为什么叫做32号，后面经我们的领队介绍后才得知。原来这是...</p>
          <a class="author" target="_blank" href="/u/b697c97db4d6?utm_campaign=maleskine&amp;utm_content=user&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
            <div class="avatar">
              <img src="//upload.jianshu.io/users/upload_avatars/6278888/41b31203-2412-47f9-ad7e-907cca7a27d5?imageMogr2/auto-orient/strip|imageView2/1/w/48/h/48" alt="48" />
            </div>
            <span class="name">嘟嘟姑姑</span>
</a>        </div>

        <div class="note have-img">
          <a class="cover" target="_blank" href="/p/b869fe58df89?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
            <img src="//upload-images.jianshu.io/upload_images/589791-a5e5a0b9136af3e4.jpg?imageMogr2/auto-orient/strip|imageView2/1/w/300/h/240" alt="240" />
</a>          <a class="title" target="_blank" href="/p/b869fe58df89?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">广州金丝带“医路相伴”项目</a>
          <p class="description"> 风雨同路，传递关爱  分享经验，共度难关</p>
          <a class="author" target="_blank" href="/u/752b816b764a?utm_campaign=maleskine&amp;utm_content=user&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
            <div class="avatar">
              <img src="//upload.jianshu.io/users/upload_avatars/589791/d76648e0161a.JPG?imageMogr2/auto-orient/strip|imageView2/1/w/48/h/48" alt="48" />
            </div>
            <span class="name">ChenSu</span>
</a>        </div>

        <div class="note have-img">
          <a class="cover" target="_blank" href="/p/6d2671125634?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
            <img src="//upload-images.jianshu.io/upload_images/4616526-3927917bf796112a.jpg?imageMogr2/auto-orient/strip|imageView2/1/w/300/h/240" alt="240" />
</a>          <a class="title" target="_blank" href="/p/6d2671125634?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">链家2017第一季度启动大会</a>
          <p class="description">领奖分享，小品舞蹈，市场形态分析，大区数据整理。大区目测200多个人，3个进入16年的精英会，1.5%的进入率。 启动大会上发的红包，里面是一张彩票…</p>
          <a class="author" target="_blank" href="/u/857f7750aacd?utm_campaign=maleskine&amp;utm_content=user&amp;utm_medium=seo_notes&amp;utm_source=recommendation">
            <div class="avatar">
              <img src="//cdn2.jianshu.io/assets/default_avatar/9-cceda3cf5072bcdd77e8ca4f21c40998.jpg?imageMogr2/auto-orient/strip|imageView2/1/w/48/h/48" alt="48" />
            </div>
            <span class="name">大连儿</span>
</a>        </div>
  </div>
</div>

    <script type="application/json" data-name="page-data">{"user_signed_in":false,"locale":"zh-CN","os":"other","read_mode":"day","read_font":"font2","note_show":{"is_martin_user":false,"is_author":false,"is_following_author":false,"is_liked_note":false,"follow_state":0,"uuid":"92aaa790-3e87-4fbc-8478-a0363893084d"},"note":{"id":3845336,"slug":"77a2e09b5285","user_id":938707,"notebook_id":4204686,"commentable":true,"likes_count":37,"views_count":6159,"public_wordage":868,"comments_count":32,"total_rewards_count":0,"is_author":false,"paid_type":"free","paid_content_accessible":false,"author":{"nickname":"向右奔跑","total_wordage":203449,"followers_count":10906,"total_likes_count":4848}}}</script>
    
    <script src="//cdn2.jianshu.io/assets/babel-polyfill-2bec152a537b07763933.js" crossorigin="anonymous"></script>
    <script src="//cdn2.jianshu.io/assets/web-base-4362f6c22e3b11930e5f.js" crossorigin="anonymous"></script>
<script src="//cdn2.jianshu.io/assets/web-a82f7ccf5dcff288588e.js" crossorigin="anonymous"></script>
    
    <script src="//cdn2.jianshu.io/assets/web/pages/notes/show/entry-bbaacc397fc28801f5b9.js" crossorigin="anonymous"></script>
    <script>
  (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      if (curProtocol === 'https') {
          bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
      }
      else {
          bp.src = 'http://push.zhanzhang.baidu.com/push.js';
      }
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
  })();
</script>

  </body>
</html>
